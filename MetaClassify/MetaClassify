#!/usr/bin/env python

# MetaClassify: launch all scheme compatible with a given dataset
# and retrieve the results of the classification or regression

__VERSION = "1.3 (Dec 21, 2006)"

import optparse, sys, os
from time import time

p = optparse.OptionParser(
  usage = "%prog --training-set INPUT [options]",
  version = "%%prog %s" % __VERSION
 )

g = optparse.OptionGroup(p, "Input")

# Training and test sets
g.add_option("--training-set", dest = "training_arff_file",
  help = "ARFF-formated training dataset")

g.add_option("--test-set", dest = "test_arff_file",
  help = """ARFF-formated test dataset. If not test dataset is provided, WEKA
will evaluate the classifiers using a 10-fold cross-validation""")

# Choice of the classifiers
g.add_option("--exclude", dest = "excluded_classifier", action = "append",
  help = "Exclude this classifier (black list)")

g.add_option("--exclude-from", dest = "excluded_classifiers_list",
  help = "Exclude the classifiers declared in this text file (one classifier per line)")

g.add_option("--only", dest = "forced_classifier", action = "append",
  help = "Only use this classifier (white list)")

g.add_option("--only-from", dest = "forced_classifiers_list",
  help = "Only use the classifiers declared in this text file (one classifier per line)")

# Use of previous run
g.add_option("--use-output", dest = "previous_output_file",
  help = """Instead of running a new analysis, extract the results from a
previously saved HTML-formated WEKA output (as generated with the '-o' option).
The original training set is requested; any test set is ignored""")

g.add_option("--use-models", dest = "previous_model_files",
  help = """Instead of building new models, use previously saved ones (option
'--save-models'). A path to the corresponding binary files is requested, using
a triple underscore '___' as a wildcard for the classifiers' name. Example:
'--use-models models/___.model'. The original training set is ignored; a test
set is required""")

p.add_option_group(g)

g = optparse.OptionGroup(p, "Modifiers")

g.add_option("-e", "--embed-in", dest = "wrapper",
  help = "Embed each classifier in the given metaclassifier")

g.add_option("-j", "--java-option", dest = "java_option", action = "append",
  help = "Option for the Java Runtime Environment")

g.add_option("--java-executable", dest = "java_executable", default = "java",
  help = "Java executable. Default: %default")

g.add_option("-w", "--weka-option", dest = "weka_option", action = "append",
  help = """Option for WEKA. Be sure to know what you're doing as some options
can interfer with MetaClassify""")

g.add_option("-q", "--quick-exit", dest = "do_allow_interrupt", action = "store_true", default = False,
  help = """If set, quit the program when pressing Control-C (instead of just
skipping the current running classifier)""")

p.add_option_group(g)

g = optparse.OptionGroup(p, "Output")

# Save output and performances
g.add_option("-o", "--output", dest = "weka_output_file",
  help = "HTML-formatted WEKA output for all the selected classifiers")

g.add_option("-p", "--performances", dest = "performances_output_file",
  help = "Output file for the performances per model (tab-delimited format)")

g.add_option("-c", "--classes", dest = "classes_output_file",
  help = "Output file for the performances per class (classification schemes only; tab-delimited format)")

# Save data for further run
g.add_option("--training-errors", dest = "do_save_training_errors", action = "store_true", default = False,
  help = """If set, the errors reported will the the ones on the training set,
and not on the test set or by cross-validation. An error will be thrown if no
training set have been used to build the model""")

g.add_option("--save-models", dest = "do_save_models", action = "store_true", default = False,
  help = """Save the built models as binary objects for further use. Only the
models on the training set are saved, not the multiple ones generated by the
cross-validation. The models are saved on the current directory as 'X.Y.model',
with 'X' the name of the training ARFF file and 'Y' the name of the classifier""")

g.add_option("--save-models-to", dest = "model_files",
  help = """Same as '--save-models', with the models saved according to the
provided pattern. You have to give a complete path, with a triple underscore
'___' that will be automatically replaced by the name of each classifier.
Example: '--save-models-to models/___.model'""")

p.add_option_group(g)

g = optparse.OptionGroup(p, "Alternative output")

g.add_option("--dump-jobs", dest = "job_filename",
  help = """If set, WEKA will not be called but a text file with the
corresponding command-lines will be generated instead. This allows to delegate
the execution of WEKA to an other computer, like a cluster. The individual
outputs of these command-lines can be reused (option '--use-output') after
concatenating them into a single file""")

p.add_option_group(g)

(p, a) = p.parse_args()

def error (msg):
	print >>sys.stderr, " ERROR: %s." % msg
	sys.exit(1)

def perror (msg):
	error("%s.\n Use '--help' for options" % msg)

#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

from lib import *

print ":: MetaClassify v%s\n" % __VERSION

# Check options compatibility
if (p.previous_output_file is not None) + \
   (p.previous_model_files is not None) + \
   (p.job_filename is not None) > 1:
	perror("Options '--use-output', '--use-models' and '--dump-jobs' can't be used together")

# Do we need to build/save new models?
p_do_build_models = (not p.previous_output_file) and (not p.previous_model_files)
p_do_save_models = (p.model_files or p.do_save_models)

if (not p_do_build_models) and (p_do_save_models):
	perror("No model can be saved if no new model is generated")

if (not p.weka_output_file) and (not p.performances_output_file) and (not p.classes_output_file):
	print " WARNING: no output will be saved."

# Do we need training and test datasets?
p_do_need_training_set = (p.previous_model_files == None) or (p.do_save_training_errors) ###?
p_do_need_test_set = (p.previous_model_files != None)

p_do_select_classifiers = True#p_do_need_training_set

# Do we need to execute WEKA?
p_do_weka_execution = (not p.job_filename)

# Do we need to parse/save the WEKA outputs?
p_do_save_weka_output = (not p.previous_output_file)

#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

# If we need a training set,
if (p_do_need_training_set):
	if (not p.training_arff_file) or (not os.path.exists(p.training_arff_file)):
		perror("An ARFF-formated training set is requested")

	print " Training dataset: %s" % p.training_arff_file

# If we need a test set,
if (p_do_need_test_set):
	if (not p.test_arff_file) or (not os.path.exists(p.test_arff_file)):
		perror("An ARFF-formated test set is requested")

# If not, we check it existence if a file is provided
else:
	if (p.test_arff_file) and (not os.path.exists(p.test_arff_file)):
		perror("File '%s' not found" % p.test_arff_file)

if (p.test_arff_file):
	print " Test dataset: %s" % p.test_arff_file

# If we need to select classifiers,
if (p_do_select_classifiers):

	# Then the classifiers inclusing/exclusion directives must be checked
	if (p.excluded_classifiers_list) and (not os.path.exists(p.excluded_classifiers_list)):
		perror("File '%s' not found" % p.excluded_classifiers_list)

	p_classifiers_black_list = {}

	if (p.excluded_classifiers_list):
		for classifier in TextReader(p.excluded_classifiers_list, False):
			p_classifiers_black_list[classifier.lower()] = True

	if (p.excluded_classifier):
		for classifier in p.excluded_classifier:
			p_classifiers_black_list[classifier.lower().strip()] = True

	if (p.forced_classifiers_list) and (not os.path.exists(p.forced_classifiers_list)):
		perror("File '%s' not found" % p.forced_classifiers_list)

	p_has_black_list = (len(p_classifiers_black_list) > 0)

	p_classifiers_white_list = {}

	if (p.forced_classifiers_list):
		for classifier in TextReader(p.forced_classifiers_list, False):
			p_classifiers_white_list[classifier.lower()] = True

	if (p.forced_classifier):
		for classifier in p.forced_classifier:
			p_classifiers_white_list[classifier.lower().strip()] = True

	p_has_white_list = (len(p_classifiers_white_list) > 0)

if (p_do_save_models):
	assert p_do_need_training_set ###

	if (p.model_files):
		if (p.model_files.find("___") == -1):
			perror("The '___' wildcard is missing for '--save-models-to'")

		p_model_files = p.model_files.replace("___", "%s")

	else:
		base = os.path.basename(p.training_arff_file)
		if base.endswith(".arff"):
			base = base[:-5]

		p_model_files = base + ".%s.model"

if (p.previous_output_file) and (not os.path.exists(p.previous_output_file)):
	perror("File '%s' not found" % p.previous_output_file)

# If models need to be loaded or saved, we check the paths
if (p.previous_model_files):
	if (p.previous_model_files.find("___") == -1):
		perror("The '___' wildcard is missing for '--use-models'")

	from glob import glob

	if (len(glob(p.previous_model_files.replace("___", '*'))) == 0):
		perror("No file match the pattern '%s'" % p.previous_model_files)

	p.previous_model_files = p.previous_model_files.replace("___", "%s")

#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

# If wee need to select classifiers,
if (p_do_select_classifiers):
	print " Load classifiers metadata ...",

	classifiers_metadata = weka_capabilities.Classifiers()
	n = len(classifiers_metadata.declared_classifiers())

	print "done (%s classifiers declared)" % n

	if (p_do_need_training_set):
		p_classifiers = classifiers_metadata.compatible_classifiers(p.training_arff_file)

		print "\n Compatibility: %s out of %s classifiers" % (len(p_classifiers), n)

		for classifier in p_classifiers:
			print "   %s" % classifier

		print

	else:
		p_classifiers = classifiers_metadata.declared_classifiers()

	if (p_has_white_list or p_has_black_list):
		final_list = p_classifiers

		if (p_has_white_list):
			final_list = filter(lambda x: x.lower() in p_classifiers_white_list, final_list)

		if (p_has_black_list):
			final_list = filter(lambda x: x.lower() not in p_classifiers_black_list, final_list)

		print " User-selected classifiers: %s" % len(final_list)

		if (len(final_list) == 0):
			print "   Done (no classifier left)."
			sys.exit(0)

		for classifier in final_list:
			print "   %s" % classifier

		p_classifiers = final_list
		print

#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

# Construction of the command using WEKA
def command_line_builder (classifier):

	weka_options = ["-i"]

	if (p.test_arff_file):
		weka_options.append("-T %s" % p.test_arff_file)

	if (p_do_save_models):
		weka_options.append("-d " + p_model_files % classifier)

	if (p.weka_option):
		weka_options.extend(p.weka_option)

	weka_options = ' '.join(weka_options)

	if (p.java_option):
		cmd = "%s %s " % (p.java_executable, ' '.join(p.java_option))
	else:
		cmd = "%s " % p.java_executable

	# launching a classifier on a test dataset
	if (p.previous_model_files):
		input_model_file = p.previous_model_files % classifier

		if (not os.path.exists(input_model_file)):
			print "error\n!  The model file '%s' didn't exists." % input_model_file
			return None

		cmd += "%s -l %s %s" % (classifier, input_model_file, weka_options)
	else:
		# launching the classifier on a training dataset
		if (p.wrapper == None):
			cmd += "%s -t %s %s" % (classifier, p.training_arff_file, weka_options)

		# launching a classifier within a meta one on a training dataset
		else:
			cmd += "%s -t %s -W %s %s --" % (p.wrapper, p.training_arff_file, classifier, weka_options)

		parameters = classifiers_metadata.get_parameters(classifier)
		if (parameters):
			cmd += ' ' + parameters

	return cmd

# Execution of a given command line
def command_line_execution (cmd):
	try:
		o = os.popen(cmd, 'r')
		data = o.readlines()
		status = o.close()

		if (status != None):
			print "error"

		return data

	except KeyboardInterrupt:
		if (p.do_allow_interrupt):
			print "exiting"
			sys.exit(0)
		else:
			print "skipping"
			return None

	except Exception, msg:
		print "error\n!  %s" % msg
		return None

#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

if (p.job_filename):
	print " Dumping command lines to '%s' ..." % p.job_filename,
	sys.stdout.flush()

	o = open(p.job_filename, 'w')

	for classifier in p_classifiers:
		cmd = command_line_builder(classifier)
		print >>o, "echo -e \"\\n<hr><h3>%s</h3>\\n<pre>\"; %s; echo -e \"</pre>\\n<code><font color=\'grey\'>%s</font></code>\"" % (classifier, cmd, cmd.replace('"', '\"'))

	o.close()

	print "done"
	sys.exit(0)

# Extraction of previously saved results
# TODO: TO PUT THIS IN 'WEKA_OUTPUT'
if (p.previous_output_file):
	report_file = open(p.previous_output_file, 'r')
	report_index = {}

	while True:
		l = report_file.readline()
		if (l == ''):
			break

		l = l.strip()

		if l.startswith("<hr><h3>weka.classifiers."):
			classifier = l[8:-5]
			report_file.readline()
			position = report_file.tell()

			report_index[classifier] = position
			continue

	def extract_output (classifier):
		if (not classifier in report_index):
			return None

		cursor = report_index[classifier]
		report_file.seek(cursor)

		data, start = [], False
		while True:
			l = report_file.readline()
			if (l == ''):
				break

			# if we reach an other classifier output, we quit
			if l.startswith("<hr><h3>"):
				return None

			# if we reach a score section, we start ...
			if l.startswith("==="):
				start = True

			# ... until we reach the end of the output
			if l.startswith("</pre>"):
				break

			if (start):
				l = l.replace("&lt;", '<')
				l = l.replace("&gt;", '>')
				data.append(l)

		return data

#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

O, P, C = None, None, None

# Preparing WEKA output
if (p.weka_output_file):
	O = open(p.weka_output_file, 'w')

	print >>O, "<h2>MetaClassify</h2>"
	header = []

	if (p_do_need_training_set):
		header.append("Training dataset: <code>%s</code>" % p.training_arff_file)

	if (p_do_need_test_set):
		header.append("Test dataset: <code>%s</code>" % p.test_arff_file)

	print >>O, "<br>\n".join(header)

# Preparing model performances output
if (p.performances_output_file):
	P = open(p.performances_output_file, 'w')
	print >>P, "Classifier	Model	%s	Time" % '	'.join(weka_output.MODELS_PERFORMANCES_SCORES)

# Preparing class performances output
if (p.classes_output_file):
	C = open(p.classes_output_file, 'w')
	print >>C, "Classifier	%s	Known	Predicted" % '	'.join(weka_output.CLASSES_PERFORMANCES_SCORES)

#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

print " Running schemes"

def rerror (msg):
	print "error"
	if (msg):
		for line in str(msg).split('\n'):
			print " ! %s" % line

for classifier in p_classifiers:

	# Run the classifier (or extract previously saved results)
	if (p.previous_output_file):
		print "   (read) %s ..." % classifier,
		sys.stdout.flush()

		w_output = extract_output(classifier)
		execution_time = ''

		if (w_output == None):
			rerror("No entry in the WEKA output for this classifier.")
			continue

	else:
		print "   %s ..." % classifier,
		sys.stdout.flush()

		cmd = command_line_builder(classifier)
		if (cmd == None):
			continue

		now = time()
		w_output = command_line_execution(cmd)
		execution_time = "%.3f" % (time() - now)

		if (w_output == None):
			continue

	if (P or C):
		try:
			w_results = weka_output.extract_classification_results(w_output, p.do_save_training_errors)

		except Exception, msg:
			rerror(msg)
			continue

		(model_type, performances, accuracy, confusion_matrix) = w_results

		if (model_type == weka_output.CLASSIFICATION_MODEL):
			model_type = "classification"
		else:
			model_type = "regression"


	print "ok"

	# Parse and save the results
	if (O):
		print >>O, "\n<hr><h3>%s</h3>" % classifier
		print >>O, "<pre>"

		for l in w_output:
			print >>O, l.replace('<', "&lt;").replace('>', "&gt;"),

		print >>O, "</pre>"
		print >>O, "<code><font color='grey'>%s</font></code>" % cmd
		O.flush()

	if (P):
		print >>P, "%s	%s	%s	%s" % (classifier, model_type, '	'.join(performances), execution_time)
		P.flush()

	if (C) and (model_type == "classification"):

		classes = [clazz for (clazz, performances) in accuracy]

		for (clazz, performances) in accuracy:
			predicted = []
			for i, value in enumerate(confusion_matrix[clazz]):
				predicted.append("%s: %s" % (classes[i], value))

			print >>C, "%s	%s	%s	%s" % (
			  classifier,
			  '	'.join(performances),
			  clazz,
			  '	'.join(predicted)
			 )

		C.flush()

print "\n Done."
