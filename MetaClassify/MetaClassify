#!/usr/bin/env python

# MetaWeka: launch all scheme compatible with a given dataset and retrieve
# the results of the classification or regression

__VERSION = "1.2c (Apr 03, 2006)"

import optparse, sys, os, time

p = optparse.OptionParser(
  usage = "%prog --training-set INPUT [options]",
  version = "%%prog %s" % __VERSION
 )

g = optparse.OptionGroup(p, "options for the input")

g.add_option("--training-set", dest = "training_arff_filename",
  help = "ARFF-formated training dataset")

g.add_option("--test-set", dest = "test_arff_filename",
  help = """ARFF-formated test dataset. If not test dataset is provided, Weka
will evaluate the performances of the classifiers through a 10-fold cross-validation""")

g.add_option("-e", "--embed-in", dest = "embed_in",
  help = "Embed each classifier in the given meta-learner")

g.add_option("--restrict-to", dest = "restrict_to", action = "append",
  help = """Allow to restrict the list of the classifiers finally selected to
the ones provided with this option (can be used several times). The final
list of classifiers is the intersection between the ones that are compatible
with the dataset and the ones declared by this option""")

g.add_option("--restrict-to-list", dest = "restrict_to_list",
  help = """Same than '--restrict-to', but read the list of the classifiers to
allow in a text file (one classifier per line)""")

g.add_option("--exclude", dest = "exclude", action = "append",
  help = """Opposite to '--restrict-to': allow you to avoid some classifiers
to be used""")

g.add_option("--exclude-list", dest = "exclude_list",
  help = """Opposite to '--restrict-to-list': allow you to avoid classifiers
from a list stored in a text file to be used""")

g.add_option("--extract-from", dest = "extract_from",
  help = """Instead of running a new analysis, extract the results from a
previously saved HTML-formated Weka output (generated with the '-o' option). If
set, '--test-set' will be ignored""")

g.add_option("--use-models", dest = "input_models_path",
  help = """Instead of running a new analysis, evaluate the performance of
previously saved Weka models. You must provide here a path to the binary files
for the models (generated with the '--save-models' options) using '%CLASSIFIER%'
as a wildcard for the classifier. Example: '--use-models models/%CLASSIFIER%.model'.
If set, '--test-set' is required and '--training-set' and '-e' are ignored""")

g.add_option("-j", "--jre-option", dest = "jre_option", action = "append",
  help = "Option for the Java Runtime Environment")

g.add_option("-w", "--weka-option", dest = "weka_option", action = "append",
  help = """Option for Weka. Be sure to know what you're doing as some options
can interfer with MetaClassify""")

p.add_option_group(g)

g = optparse.OptionGroup(p, "options for the output")

g.add_option("-s", "--scores", dest = "scores_report_filename",
  help = "Output file for the classifiers' scores (tab-delimited format)")

g.add_option("-o", "--output", dest = "weka_output_filename",
  help = "Output file for the Weka classifiers output (HTML format)")

g.add_option("-c", "--classes", dest = "classes_report_filename",
  help = "Output file for the accuracy by class scores (tab-delimited format)")

g.add_option("--training-errors", dest = "training_errors", action = "store_true", default = False,
  help = """If set, the errors reported will the the ones on the training set,
and not on the test set or by cross-validation. An error will be thrown if no
training set have been used to build the model""")

g.add_option("--save-models", dest = "save_models", action = "store_true", default = False,
  help = """If set, ask Weka to save the Java object of the model for each
classifier (only the model on the training set is saved, not the multiple ones
generated by the cross-validation). The models are saved on the current directory
under this name: X.Y.model, where 'X' is the name of the training ARFF file and
'Y' the name of the classifier""")

g.add_option("--save-models-as", dest = "output_models_path",
  help = """Same effect than '--save-models', but allow to precise how the
models must be saved. You have to give a complete path, including '%CLASSIFIER%'
somewhere (this will be replaced by the name of the classifier. Example:
'--save-models-as models/my_project.%CLASSIFIER%.model'""")

g.add_option("--create-sge-job", dest = "sge_job_name",
  help = """If set, a shell script file (SGD_JOB_NAME.sh) will be generated in
order to run each classifier on a grid's node by using the Sun Grid Engine (SGE)
framework. When the job is completed an HTML-formated file usable with the
'--extract-from' option is created (SGD_JOB_NAME.html). SGD_JOB_NAME must
contains only letters or digits. If set, '-s', '-o', 'c' and '--extract-from'
will be ignored""")

g.add_option("--sge-option", dest = "sge_option", action = "append",
  help = "Option for the SGE tasks created with '--create-sge-job'")

p.add_option_group(g)

CWD = os.path.abspath(os.path.dirname(sys.argv[0]))

p.add_option("--classifiers-properties", dest = "classifiers_properties",
  default = os.path.join(CWD, "weka", "classifiers.properties"), help = optparse.SUPPRESS_HELP)

p.add_option("--classifiers-parameters", dest = "classifiers_parameters",
  default = os.path.join(CWD, "weka", "classifiers.parameters"), help = optparse.SUPPRESS_HELP)

p.add_option("--quick-exit", dest = "allow_interrupt", action = "store_true", default = False,
  help = """If set, exit the program when pressing Control-C instead of just
skipping the current classifier""")

(p, a) = p.parse_args()

def perror (msg):
	print >>sys.stderr, " %s.\n Use '--help' for options." % msg
	sys.exit(1)

if (not p.input_models_path):
	if (not p.training_arff_filename) or (not os.path.exists(p.training_arff_filename)):
		perror("An ARFF-formated training dataset is required")
else:
	if (not p.test_arff_filename) or (not os.path.exists(p.test_arff_filename)):
		perror("An ARFF-formated test dataset is required")

	if (p.training_errors):
		perror("Extraction of errors on training set is not possible when starting from a previously saved model")

	p.training_arff_filename = p.test_arff_filename

if (not p.extract_from) and (p.test_arff_filename) and (not os.path.exists(p.test_arff_filename)):
	perror("Invalid test set file: '%s'" % p.test_arff_filename)

if (not p.sge_job_name):
	if (p.extract_from != None) and (not os.path.exists(p.extract_from)):
		perror("Unknown report file '%s'" % p.extract_from)

	if (p.scores_report_filename == None):
		perror("At least one output file is required to store scores")

if p.restrict_to_list and (not os.path.exists(p.restrict_to_list)):
	perror("The file '%s' didn't exists" % p.restrict_to_list)

if p.exclude_list and (not os.path.exists(p.exclude_list)):
	perror("The file '%s' didn't exists" % p.exclude_list)

if p.input_models_path:
	if (p.input_models_path.find("%CLASSIFIER%") == -1):
		perror("The '%CLASSIFIER%' wildcard is missing for --use-models")

	import glob
	if (len(glob.glob(p.input_models_path.replace("%CLASSIFIER%", '*'))) == 0):
		perror("No file match the pattern '%s'" % p.input_models_path)

	p.input_models_path = p.input_models_path.replace("%CLASSIFIER%", "%s")

if p.output_models_path:
	p.save_models = True

	if (p.output_models_path.find("%CLASSIFIER%") == -1):
		perror("The '%CLASSIFIER%' wildcard is missing for --save-models-as")

	p.output_models_path = p.output_models_path.replace("%CLASSIFIER%", "%s")

if p.sge_job_name:
	import string
	allowed_characters = string.letters + string.digits + '.+'

	for c in p.sge_job_name:
		if (not c in allowed_characters):
			perror("Invalid job name '%s'" % p.sge_job_name)

#::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

print ":: MetaClassify v%s\n" % __VERSION

from weka import meta, utils

print " Reading meta-informations on classifiers ...",

CLASSIFIERS_PARAMETERS = {}

for (classifier, parameters) in utils.TextReader(p.classifiers_parameters):
	CLASSIFIERS_PARAMETERS[classifier] = parameters

mw = meta.Classifiers(p.classifiers_properties)
n = len(mw.declared_classifiers())

print "done (%s classifiers declared)" % n

if (not p.input_models_path):
	print " Training dataset: %s" % p.training_arff_filename

if (p.test_arff_filename):
	print " Test dataset: %s" % p.test_arff_filename

print " Determining dataset type ...",

try:
	dataset = meta.Dataset(p.training_arff_filename)

except Exception, msg:
	print >>sys.stderr, " Error while reading the dataset.\n %s" % msg
	sys.exit(1)

CLASS, ATTRIBUTES = dataset.get_class(), dataset.get_attributes()

attributes_type = {}
for type, name in ATTRIBUTES:
	attributes_type[type] = True

print "done (class: %s, attributes: %s)" % (CLASS[0], " and ".join(attributes_type.keys()))

classifiers = mw.compatible_classifiers(CLASS, ATTRIBUTES)

print "\n Compatibility: %s/%s classifiers" % (len(classifiers), n)

for classifier in classifiers:
	print "   %s" % classifier

print

# Managing user-provided white- and black-list of classifiers
white_list = {}

if (p.restrict_to_list):
	for classifier in utils.TextReader(p.restrict_to_list, False):
		white_list[classifier.lower()] = True

if (p.restrict_to):
	for classifier in p.restrict_to:
		white_list[classifier.lower().strip()] = True

black_list = {}

if (p.exclude_list):
	for classifier in utils.TextReader(p.exclude_list, False):
		black_list[classifier.lower()] = True

if (p.exclude):
	for classifier in p.exclude:
		black_list[classifier.lower().strip()] = True


has_white_list = (len(white_list) > 0)
has_black_list = (len(black_list) > 0)

if (has_white_list or has_black_list):
	final_list = classifiers

	if has_white_list:
		final_list = filter(lambda x: x.lower() in white_list, final_list)

	if has_black_list:
		final_list = filter(lambda x: x.lower() not in black_list, final_list)

	print " Chosen classifiers: %s" % len(final_list)

	if (len(final_list) == 0):
		print "   Done."
		sys.exit(0)

	for classifier in final_list:
		print "   %s" % classifier

	classifiers = final_list
	print

#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

# Construction of the command using Weka
if p.output_models_path:
	output_model_file = p.output_models_path
else:
	base = os.path.basename(p.training_arff_filename)
	if base.endswith(".arff"):
		base = base[:-5]

	output_model_file = base + ".%s.model"

def prepare_cmd (classifier):
	weka_options = ["-i"]

	if p.test_arff_filename:
		weka_options.append("-T %s" % p.test_arff_filename)

	if p.save_models:
		weka_options.append("-d " + output_model_file % classifier)

	if p.weka_option:
		weka_options.extend(p.weka_option)

	weka_options = ' '.join(weka_options)

	if p.jre_option:
		cmd = "java %s " % ' '.join(p.jre_option)
	else:
		cmd = "java "

	# launching a classifier on a test dataset
	if (p.input_models_path):
		input_model_file = p.input_models_path % classifier

		if (not os.path.exists(input_model_file)):
			print "error\n!  The model file '%s' didn't exists." % input_model_file
			return None

		cmd += "%s -l %s %s" % (classifier, input_model_file, weka_options)
	else:
		# launching the classifier on a training dataset
		if (p.embed_in == None):
			cmd += "%s -t %s %s" % (classifier, p.training_arff_filename, weka_options)

		# launching a classifier within a meta one on a training dataset
		else:
			cmd += "%s -t %s -W %s %s --" % (p.embed_in, p.training_arff_filename, classifier, weka_options)

		if (classifier in CLASSIFIERS_PARAMETERS):
			cmd += ' ' + CLASSIFIERS_PARAMETERS[classifier]

	return cmd

# Preparation of jobs to run with SGE
if (p.sge_job_name):
	print " Preparing jobs for SGE ...",

	script_filename = "%s.sh" % p.sge_job_name
	script = open(script_filename, 'w')

	print >>script, "#!/bin/sh"
	print >>script, "# Launcher for '%s' (MetaClassify)" % p.sge_job_name

	# dispatch
	print >>script, '\n#' + ':' * 79
	print >>script, "qsub << DISPATCH_SCRIPT_END\n"

	print >>script, "#$ -S /bin/sh"
	print >>script, "#$ -t 1-%s:2" % (len(classifiers) * 2 - 1)
	print >>script, "#$ -N %s" % p.sge_job_name
	print >>script, "#$ -cwd"

	if (p.sge_option):
		for option in p.sge_option:
			print >>script, "#$ %s" % option

	print >>script, "\nparameters=("

	for classifier in classifiers:
		cmd = prepare_cmd(classifier)

		print >>script, "  \"%s\"" % classifier
		print >>script, "  \"%s\"" % cmd.replace('"', '\"')

	print >>script, " )\n"

	print >>script, "classifier=\${parameters[\$SGE_TASK_ID-1]}"
	print >>script, "cmd=\${parameters[\$SGE_TASK_ID]}"

	print >>script, "\necho"
	print >>script, "echo \"<hr><h3>\$classifier</h3>\""
	print >>script, "echo \"<pre>\""
	print >>script, "eval \$cmd"
	print >>script, "echo \"</pre>\""
	print >>script, "echo \"<code><font color=\'grey\'>\$cmd</font></code>\""

	print >>script, "DISPATCH_SCRIPT_END"

	# finalize
	print >>script, '\n#' + ':' * 79
	print >>script, "qsub << FINALIZE_SCRIPT_END\n"

	print >>script, "#$ -S /bin/sh"
	print >>script, "#$ -N %s.finalize" % p.sge_job_name
	print >>script, "#$ -hold_jid %s" % p.sge_job_name
	print >>script, "#$ -o /dev/null"
	print >>script, "#$ -e /dev/null"
	print >>script, "#$ -cwd"

	print >>script, "\ncat %s.o*.* > %s.html\n" % (p.sge_job_name, p.sge_job_name)

	print >>script, "rm %s.o*.*" % p.sge_job_name
	print >>script, "rm `find . -name \"%s.e*.*\" -size 0c`" % p.sge_job_name

	print >>script, "FINALIZE_SCRIPT_END"

	print >>script, "\necho \"----\""
	print >>script, "echo \"  Note: the task '%s' is complete only\"" % p.sge_job_name
	print >>script, "echo \"  when the file '%s.html' is created.\"" % p.sge_job_name
	print >>script, "echo"

	script.close()
	os.chmod(script_filename, 0744)

	print "ok (script '%s' created)" % script_filename

	print "\n Done."
	sys.exit(0)

# Execution of a given command line
def execute_cmd (cmd):
	try:
		o = os.popen(cmd, 'r')
		data = o.readlines()
		status = o.close()

		if (status != None):
			print "error"

		return data

	except KeyboardInterrupt:
		if (p.allow_interrupt):
			print "exiting"
			sys.exit(0)
		else:
			print "skipping"
			return None

	except Exception, msg:
		print "error\n!  %s" % msg
		return None

# Extraction of previously saved results
if (p.extract_from):
	report_file = open(p.extract_from, 'r')
	report_index = {}

	while True:
		l = report_file.readline()
		if (l == ''):
			break

		l = l.strip()

		if l.startswith("<hr><h3>weka.classifiers"):
			classifier = l[8:-5]
			report_file.readline()
			position = report_file.tell()

			report_index[classifier] = position
			continue

	def extract_output (classifier):
		if (not classifier in report_index):
			return None

		cursor = report_index[classifier]
		report_file.seek(cursor)

		data, start = [], False
		while True:
			l = report_file.readline()
			if (l == ''):
				break

			# if we reach an other classifier output, we quit
			if l.startswith("<hr><h3>"):
				return None

			# if we reach a score section, we start ...
			if l.startswith("==="):
				start = True

			# ... until we reach the end of the output
			if l.startswith("</pre>"):
				break

			if (start):
				l = l.replace("&lt;", '<')
				l = l.replace("&gt;", '>')
				data.append(l)

		return data

#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: Main loop

from weka import parsing

print " Running schemes"

scores_report = open(p.scores_report_filename, 'w')
weka_output = None
accuracy_report = None

print >>scores_report, "# Classifier	Model	%s	Time" % '	'.join(parsing.CLASSIFICATION_PERFORMANCE_KEYWORDS)

if (p.weka_output_filename != None):
	weka_output = open(p.weka_output_filename, 'w')

	print >>weka_output, "<h2>MetaClassify</h2>"
	datasets = []

	if (not p.input_models_path):
		datasets.append("Training dataset: <code>%s</code>" % p.training_arff_filename)

	if (p.test_arff_filename):
		datasets.append("Test dataset: <code>%s</code>" % p.test_arff_filename)

	print >>weka_output, "<br>\n".join(datasets)

if (p.classes_report_filename != None):
	accuracy_report = open(p.classes_report_filename, 'w')

	print >>accuracy_report, "# Classifier	%s	Known	Predicted" % '	'.join(parsing.CLASSIFICATION_ACCURACY_KEYWORDS)

def error (msg):
	print "error"
	if (msg != None):
		for line in str(msg).split('\n'):
			print " ! %s" % line

for classifier in classifiers:

	print "   %s ..." % classifier,
	sys.stdout.flush()

	# Getting classification results
	start = time.time()

	if (p.extract_from):
		print "(from previous report)",

		output = extract_output(classifier)
		if (output == None):
			error("No entry in the WEKA output for this classifier.")
			continue

	else:
		cmd = prepare_cmd(classifier)
		if (cmd == None):
			continue

		output = execute_cmd(cmd)
		if (output == None):
			continue

		if weka_output:
			print >>weka_output, "\n<hr><h3>%s</h3>" % classifier
			print >>weka_output, "<pre>"

			for line in output:
				line = line.replace('<', "&lt;")
				line = line.replace('>', "&gt;")
				print >>weka_output, line,

			print >>weka_output, "</pre>"
			print >>weka_output, "<code><font color='grey'>%s</font></code>" % cmd

			weka_output.flush()

	stop = time.time()

	# Parsing of the output
	try:
		results = parsing.extract_classification_results(output, p.training_errors)
		(model_type, performances, accuracy, confusion_matrix) = results

	except Exception, msg:
		error(msg)
		continue

	# Scores report
	if (model_type == parsing.CLASSIFICATION_MODEL):
		mt = "classification"
	else:
		mt = "regression"

	print >>scores_report, "%s	%s	%s	%.3f" % (classifier, mt, '	'.join(performances), (stop - start))

	scores_report.flush()
	print "ok"

	# Accuracy report
	if (model_type == parsing.CLASSIFICATION_MODEL) and accuracy_report:
		classes = [clazz for (clazz, performances) in accuracy]

		for (clazz, performances) in accuracy:
			predicted = []
			for i, value in enumerate(confusion_matrix[clazz]):
				predicted.append("%s: %s" % (classes[i], value))

			print >>accuracy_report, "%s	%s	%s	%s" % (classifier, '	'.join(performances), clazz, '	'.join(predicted))

		accuracy_report.flush()

print "\n Done."
